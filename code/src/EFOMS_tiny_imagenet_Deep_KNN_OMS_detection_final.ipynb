{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e88ded8",
   "metadata": {},
   "source": [
    "### *Module Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import faiss\n",
    "from subprocess import PIPE, run\n",
    "from IPython.display import display as ip_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbc82f",
   "metadata": {},
   "source": [
    "### *External Module Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_modules_path = '..\\\\nn_likelihood_modules'\n",
    "sys.path.append(external_modules_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_network_structure import *\n",
    "from common_imports import *\n",
    "from common_use_functions import *\n",
    "from constant import *\n",
    "from defined_data_structure import *\n",
    "from defined_network_structure import *\n",
    "from experim_neural_network import *\n",
    "from experim_preparation import *\n",
    "from generate_activation_level import *\n",
    "from pytorch_model_predict import *\n",
    "from vector_preprocessing import *\n",
    "from ResNet import *\n",
    "from experim_ResNet import *\n",
    "from cifar_10_data_prep import *\n",
    "from pytorch_swintransformer_modified import *\n",
    "from tiny_imagenet_data_prep import *\n",
    "from sensitivity_analysis import *\n",
    "from deep_KNN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc22ef",
   "metadata": {},
   "source": [
    "### *GPU verification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nb_gpu = torch.cuda.device_count()\n",
    "if nb_gpu > 0:\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701537f",
   "metadata": {},
   "source": [
    "### *Working directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current path\n",
    "current_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c8167",
   "metadata": {},
   "source": [
    "### *Load configurations and data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All the parameters in this part should be configured\n",
    "\"\"\"\n",
    "# Experience path\n",
    "experim_path = current_path\n",
    "\n",
    "# File extensions\n",
    "json_ext = '.json'\n",
    "np_ext = '.npy'\n",
    "csv_ext = '.csv'\n",
    "\n",
    "# ResNet model prefix\n",
    "model_name_prefix = 'swin'\n",
    "\n",
    "# Image max pixel value\n",
    "image_max_pix_val = 255\n",
    "\n",
    "# Tested sets name\n",
    "train_set_name = 'train'\n",
    "test_set_name = 'test'\n",
    "valid_set_name = 'valid'\n",
    "input_extension = 'X'\n",
    "label_extension = 'Y'\n",
    "\n",
    "# Save paths\n",
    "model_save_path = path_join(experim_path, 'experim_models_swin')\n",
    "\n",
    "\"\"\"\n",
    "The following parameters should be configured according to your experiments\n",
    "\"\"\"\n",
    "\n",
    "# Trained model name \n",
    "trained_net_name = 'swin_b_v2_1024' # You can select any model from the \"experim_models_swin\" folder\n",
    "\n",
    "# ResNet related params\n",
    "net_model_name = 'swin_b_v2_1024'# The model name should be coherent with your chosen model\n",
    "\n",
    "# Tiny-imagenet datafolder path\n",
    "tiny_imagenet_path = 'D:\\\\Doctorat\\\\research\\\\Tiny_imagenet_experim\\\\tiny-imagenet-200-reform\\\\'\n",
    "tiny_imagenet_val_path = path_join(tiny_imagenet_path, 'reform_val')\n",
    "tiny_imagenet_train_path = path_join(tiny_imagenet_path, 'reform_train')\n",
    "\n",
    "# Tiny-imagenet-c datafolder path\n",
    "tiny_imagenet_c_path = 'D:\\\\Doctorat\\\\research\\\\Tiny_imagenet_experim\\\\Tiny-ImageNet-C-reform\\\\'\n",
    "\n",
    "# Dataset general informations\n",
    "data_set_infos = {\n",
    "    'nb_classes' : 200\n",
    "}\n",
    "\n",
    "# Distance decision filtering threshold\n",
    "std_threshold_coeff = 2\n",
    "\n",
    "# The method to determining the significant neurons (mean or most_common)\n",
    "sobol_filter_method = 'mean'\n",
    "\n",
    "# The end number used for the \"top\" filtering method (1 means we want the top-1, 2 for top-2 etc.)\n",
    "top_index_end = 1\n",
    "\n",
    "# Rscript launch params\n",
    "Rscript_path = 'C:\\\\Program Files\\\\R\\\\R-4.3.3\\\\bin\\\\Rscript.exe'\n",
    "\n",
    "# The number of considered k-nearst neighbors\n",
    "k = 200\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# The output folder\n",
    "output_path = path_join(experim_path, 'output')\n",
    "\n",
    "# Build the class list\n",
    "class_list = list(range(data_set_infos['nb_classes']))\n",
    "\n",
    "# Batch size for the dataloader creation\n",
    "torch_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folders\n",
    "create_directory(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ae1fb",
   "metadata": {},
   "source": [
    "### *Experiment preparation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55636cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tiny imagenet training set and test set\n",
    "tiny_imagenet_train_dataset, tiny_imagenet_test_dataset = get_tiny_imagenet_without_transform(tiny_imagenet_train_path, tiny_imagenet_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names of the filtering results\n",
    "column_names_OOD_filtering = ['transformation', 'nb_examples', 'nb_OOD', 'nb_InD', 'total_acc', 'OOD_acc', 'InD_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9931900",
   "metadata": {},
   "source": [
    "### *Load the trained Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network\n",
    "trained_net = load_model_by_net_name(model_save_path, trained_net_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a79b0",
   "metadata": {},
   "source": [
    "### *Move the model to GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to gpu\n",
    "trained_net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21678192",
   "metadata": {},
   "source": [
    "### *Tiny imagenet dataset preparation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a90a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader building\n",
    "train_loader = create_loader_from_torch_dataset(tiny_imagenet_train_dataset, batch_size=torch_batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = create_loader_from_torch_dataset(tiny_imagenet_test_dataset, batch_size=torch_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13de364",
   "metadata": {},
   "source": [
    "### *Evaluate the activation levels for the original training and test sets of Tiny-Imagenet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set activation levels \n",
    "train_actLevels = obtain_activation_levels(trained_net,\n",
    "                                           train_loader, 'train', with_predict_class=True, loss_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924888a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the test set activation levels \n",
    "test_actLevels = obtain_activation_levels(trained_net,\n",
    "                                           test_loader, 'test', with_predict_class=True, loss_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817aa90e",
   "metadata": {},
   "source": [
    "### *Sobol index evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hidden layer Id\n",
    "last_hidden_layerId = list(train_actLevels['actLevel'].keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60628992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correctly predicted index\n",
    "correctly_predicted_bools = train_actLevels['class'] == train_actLevels['predict_class']\n",
    "# Get the corresponding data\n",
    "last_hidden_actLevels = train_actLevels['actLevel'][last_hidden_layerId][correctly_predicted_bools.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last layer parameters\n",
    "model_params = get_model_parameters(trained_net, to_numpy=True)\n",
    "final_linear_params = model_params['head_out.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08591daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of weight and input\n",
    "# Copy the original activation levels and weights\n",
    "normalized_last_hidden_actLevel = copy.deepcopy(last_hidden_actLevels)\n",
    "upped_final_linear_params = copy.deepcopy(final_linear_params)\n",
    "# Check the min and max values of each neuron\n",
    "last_hidden_actLevel_max = np.max(last_hidden_actLevels, axis=0)\n",
    "last_hidden_actLevel_min = np.min(last_hidden_actLevels, axis=0) # Not used, just for verification\n",
    "# Iterate over the maximum values and normalize the input\n",
    "for index, neuron_max in enumerate(last_hidden_actLevel_max):\n",
    "    if neuron_max != 0:\n",
    "        normalized_last_hidden_actLevel[:,index] = normalized_last_hidden_actLevel[:,index] / neuron_max\n",
    "        upped_final_linear_params['weight'][:,index] = upped_final_linear_params['weight'][:,index] * neuron_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a670e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the final linear parameters per class and assign the real data\n",
    "used_linear_params = upped_final_linear_params\n",
    "data = normalized_last_hidden_actLevel\n",
    "# Number of variables\n",
    "nb_vars = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1646e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the X and y for the sobol index evaluation in R\n",
    "# Get the neuron names\n",
    "neuron_names = ['neuron_'+str(index) for index in range(nb_vars)]\n",
    "# Build the X dataframe\n",
    "R_X = pd.DataFrame(data, columns=neuron_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f356b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataframe that stores weights and bias\n",
    "R_network_params_weight_columns = [*(['weight_'+str(index) for index in range(used_linear_params['weight'].shape[1])])]\n",
    "R_network_params_bias_columns = [*(['bias_'+str(index) for index in range(used_linear_params['bias'].shape[0])])]\n",
    "R_network_params_weights = pd.DataFrame(used_linear_params['weight'], columns=R_network_params_weight_columns)\n",
    "R_network_params_bias = pd.DataFrame(used_linear_params['bias'].reshape(1,-1), columns=R_network_params_bias_columns)\n",
    "save_df_to_csv(path_join(output_path, 'R_network_params_weight.csv'),R_network_params_weights)\n",
    "save_df_to_csv(path_join(output_path, 'R_network_params_bias.csv'),R_network_params_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size\n",
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb24ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two random samples from R_X\n",
    "A_index = generate_sample_index(data, N, replace=False)\n",
    "B_index = generate_sample_index_exclude_items(data, N, A_index, replace=False)\n",
    "R_X_A = R_X.loc[A_index,:].copy(deep=True).reset_index(drop=True)\n",
    "R_X_B = R_X.loc[B_index,:].copy(deep=True).reset_index(drop=True)\n",
    "# Save the random samples from R_X\n",
    "save_df_to_csv(path_join(output_path, 'R_X_A.csv'),R_X_A)\n",
    "save_df_to_csv(path_join(output_path, 'R_X_B.csv'),R_X_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c28b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could choose sobolrank (only first order indices), sobolEff (first and total indices) or shapleysobol_knn (first and total indices)\n",
    "R_sobol_method = 'sobolmultout'\n",
    "R_sobol_script = path_join(experim_path, R_sobol_method+'_eval.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the R script (The path to read the data is given as arguments (i.e., experim_path+'\\\\'))\n",
    "ouput_R = run([Rscript_path, '--vanilla', R_sobol_script, output_path+'\\\\', str(data_set_infos['nb_classes'])], shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the important variables per class\n",
    "# Initialize the determined variables as None\n",
    "important_variables = None\n",
    "if R_sobol_method == 'sobolmultout':\n",
    "    # Load the sobol indices (first and total) and convert it to a dictionary\n",
    "    R_first_order_sobol_indices = read_csv_to_pd_df(path_join(output_path, R_sobol_method+'_fs'+csv_ext))\n",
    "    R_total_order_sobol_indices = read_csv_to_pd_df(path_join(output_path, R_sobol_method+'_tt'+csv_ext))\n",
    "    R_first_order_sobol_dict = R_first_order_sobol_indices['original'].to_dict()\n",
    "    R_total_order_sobol_dict = R_total_order_sobol_indices['original'].to_dict()\n",
    "    # Get the important variables per class\n",
    "    important_variables = important_variables_R_first_and_total_order_analysis_multout_ver(R_first_order_sobol_dict, \n",
    "                                                                                           R_total_order_sobol_dict,\n",
    "                                                                                           filter_method=sobol_filter_method,\n",
    "                                                                                           divide_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the dataframe that contains the number of neurons\n",
    "nb_important_vars = len(list(important_variables.keys()))\n",
    "determined_nb_important_vars = None\n",
    "if sobol_filter_method != 'top_portion' and sobol_filter_method != 'beside_end_portion':\n",
    "    determined_nb_important_vars = [[nb_vars, nb_important_vars, sobol_filter_method]]\n",
    "else:\n",
    "    determined_nb_important_vars = [[nb_vars, nb_important_vars, sobol_filter_method+'_'+sobol_divide_factor]]\n",
    "determined_nb_important_vars_df = pd.DataFrame(determined_nb_important_vars, columns=['nb_neurons', 'nb_important_neurons', 'sobol_filter_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the sorted total important variable(neuron) indices\n",
    "sorted_important_vars = sorted(list(important_variables))\n",
    "# Build the mapping dictionary to modify neuron indices\n",
    "important_var_map_dict = build_map_to_index_dict(important_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the important variables\n",
    "store_dict_as_json(path_join(output_path, trained_net_name+'_important_neurons.json'), important_variables)\n",
    "save_df_to_csv(path_join(output_path, trained_net_name+'_nb_important_neurons.csv'), determined_nb_important_vars_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c44c8b",
   "metadata": {},
   "source": [
    "### *Load the distribution shift OOD dataset (Tiny-imagenet-c) and evaluate the activation levels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the Tiny-imagnet-c dataset\n",
    "# Get the content in the folder\n",
    "transformation_types = [transformation_type for transformation_type in contents_of_folder(tiny_imagenet_c_path)]\n",
    "# Load all the transformation datasets\n",
    "load_tiny_imagenet_c_datasets = {}\n",
    "for transformation_type in transformation_types:\n",
    "    load_tiny_imagenet_c_datasets[transformation_type] = datasets.ImageFolder(\n",
    "                                                        root=path_join(tiny_imagenet_c_path, transformation_type),\n",
    "                                                        transform=v2.Compose([v2.ToTensor()]),\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a Tiny-imagenet-c example\n",
    "plt.imshow(load_tiny_imagenet_c_datasets['brightness_2'][1300][0].permute(1,2,0), interpolation='nearest')\n",
    "plt.show()\n",
    "print(load_tiny_imagenet_c_datasets['brightness_2'][1300][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfa8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataloader and evaluate the activation levels\n",
    "distrib_shift_actLevels = {}\n",
    "for transformation_type in list(load_tiny_imagenet_c_datasets.keys()):\n",
    "    # Build the loader         \n",
    "    current_transformed_loader = create_loader_from_torch_dataset(load_tiny_imagenet_c_datasets[transformation_type],\n",
    "                                                                  batch_size=torch_batch_size, shuffle=False, num_workers=0)\n",
    "    # Evaluate the activation levels\n",
    "    distrib_shift_actLevels[transformation_type] = obtain_activation_levels(trained_net, current_transformed_loader,\n",
    "                                                                            transformation_type, with_predict_class=True,\n",
    "                                                                            loss_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2231ffd",
   "metadata": {},
   "source": [
    "### *Determine the correctly predicted training examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e146ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indicating the correctly predicted training examples\n",
    "correct_train_actLevels = build_correct_actLevels(train_actLevels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b8bc8",
   "metadata": {},
   "source": [
    "### *Prepare the normalized feature vectors with all neurons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training set normalized feature vectors (only the correctly predicted examples)\n",
    "correct_train_zs = normalize_feature_vecs_knn(correct_train_actLevels, last_hidden_layerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training set normalized feature vectors\n",
    "train_zs = normalize_feature_vecs_knn(train_actLevels, last_hidden_layerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4af08-3ca9-41d3-9594-0bcb67a4cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the test set normalized feature vectors\n",
    "test_zs = normalize_feature_vecs_knn(test_actLevels, last_hidden_layerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab956ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the normalized feature vectors of the distribution shift ood set\n",
    "distrib_shift_zs = {}\n",
    "for transform_type in distrib_shift_actLevels:\n",
    "    distrib_shift_zs[transform_type] = normalize_feature_vecs_knn(distrib_shift_actLevels[transform_type], last_hidden_layerId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c51ae",
   "metadata": {},
   "source": [
    "### *Prepare the Deep k-nearst neighbors OOD detection with all neurons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the faiss train set index\n",
    "train_index = faiss.IndexFlatL2(correct_train_zs.shape[1])\n",
    "train_index.add(correct_train_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train set k-nearst neighbor scores\n",
    "correct_train_S = k_nearst_neighbor_scores(train_index, correct_train_zs, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887589a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std of the test scores\n",
    "threshold_S_mean, threshold_S_std = get_mean_std(correct_train_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the threshold\n",
    "threshold = threshold_S_mean - std_threshold_coeff * threshold_S_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33823685",
   "metadata": {},
   "source": [
    "### *Deep k-nearst neighbors OOD evaluation result headers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_ood_eval_headers = ['set_name', 'nb_ood', 'nb_ind', 'ood_percent', 'ind_percent', 'acc_total', 'acc_ood', 'acc_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4674611",
   "metadata": {},
   "source": [
    "### *Evaluate the test accuracy after applying the OOD detection with all neurons on the original dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ood results on the original datasets\n",
    "origin_ood_eval_results = []\n",
    "# The ood detection evaluation on the training set\n",
    "train_ood_eval_result = experim_ood_detection_knn(train_index, train_zs, train_actLevels, k, threshold, 'train')\n",
    "# Display jump line\n",
    "print()\n",
    "# The ood detection evaluation on the test set\n",
    "test_ood_eval_result = experim_ood_detection_knn(train_index, test_zs, test_actLevels, k, threshold, 'test')\n",
    "# Add the evaluation results\n",
    "origin_ood_eval_results.append(train_ood_eval_result)\n",
    "origin_ood_eval_results.append(test_ood_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fdafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train ood evaluation results\n",
    "save_list_to_csv(path_join(output_path, 'origin_ood_eval_results'+csv_ext), origin_ood_eval_results, headers=knn_ood_eval_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68ee99",
   "metadata": {},
   "source": [
    "### *Deep k-nearst neighbors OOD detection on distribution shift dataset (Tiny-imagenet-c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ood detection evaluation\n",
    "distrib_shift_eval_results = []\n",
    "for transform_type in distrib_shift_zs:\n",
    "    current_eval_result = experim_ood_detection_knn(train_index, distrib_shift_zs[transform_type],\n",
    "                                                    distrib_shift_actLevels[transform_type], k, threshold, transform_type)\n",
    "    distrib_shift_eval_results.append(current_eval_result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the distribution shift ood evaluation results\n",
    "save_list_to_csv(path_join(output_path, 'distrib_shift_ood_eval_results'+csv_ext), distrib_shift_eval_results, headers=knn_ood_eval_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e5fe7",
   "metadata": {},
   "source": [
    "### *Prepare the normalized feature vectors with only the significant neurons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfae7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the normalized feature vectors according to the significant neurons of each class for the search index building\n",
    "correct_train_zs_sig = build_sig_zs(correct_train_actLevels, last_hidden_layerId, sorted_important_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the normalized feature vectors according to the significant neurons of each class for the training set\n",
    "train_zs_sig = build_sig_zs(train_actLevels, last_hidden_layerId, sorted_important_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e81c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the normalized feature vectors according to the significant neurons of each class for the test set\n",
    "test_zs_sig = build_sig_zs(test_actLevels, last_hidden_layerId, sorted_important_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7372f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the normalized feature vectors from the significant neurons for the distribution shift ood set\n",
    "distrib_shift_zs_sig = {}\n",
    "for transform_type in distrib_shift_actLevels:\n",
    "    distrib_shift_zs_sig[transform_type] = build_sig_zs(distrib_shift_actLevels[transform_type], last_hidden_layerId, sorted_important_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e745ea",
   "metadata": {},
   "source": [
    "### *Prepare the Deep k-nearst neighbors OOD detection with the significant neurons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the faiss train set index\n",
    "train_index_sig = faiss.IndexFlatL2(correct_train_zs_sig.shape[1])\n",
    "train_index_sig.add(correct_train_zs_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70151a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scores over different classes\n",
    "correct_train_S_sig = k_nearst_neighbor_scores(train_index_sig, correct_train_zs_sig, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std of the train scores\n",
    "threshold_S_mean_sig, threshold_S_std_sig = get_mean_std(correct_train_S_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the threshold\n",
    "threshold_sig = threshold_S_mean_sig - std_threshold_coeff * threshold_S_std_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa8c52",
   "metadata": {},
   "source": [
    "### *Evaluate the test accuracy after applying the OOD detection with the significant neurons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52885707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ood results on the original datasets\n",
    "sig_origin_ood_eval_results = []\n",
    "# The ood detection evaluation on the training set\n",
    "sig_train_ood_eval_result = experim_ood_detection_knn(train_index_sig, train_zs_sig, train_actLevels, k, threshold_sig, 'train')\n",
    "# Display jump line\n",
    "print()\n",
    "# The ood detection evaluation on the test set\n",
    "sig_test_ood_eval_result = experim_ood_detection_knn(train_index_sig, test_zs_sig, test_actLevels, k, threshold_sig, 'test')\n",
    "# Add the evaluation results\n",
    "sig_origin_ood_eval_results.append(sig_train_ood_eval_result)\n",
    "sig_origin_ood_eval_results.append(sig_test_ood_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train ood evaluation results\n",
    "save_list_to_csv(path_join(output_path, 'sig_origin_ood_eval_results'+csv_ext), sig_origin_ood_eval_results, headers=knn_ood_eval_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210b44f",
   "metadata": {},
   "source": [
    "### *Deep k-nearst neighbors OOD detection with only the significant neurons on distribution shift dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c55c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The ood detection evaluation\n",
    "sig_distrib_shift_eval_results = []\n",
    "for transform_type in distrib_shift_zs:\n",
    "    current_eval_result = experim_ood_detection_knn(train_index_sig, distrib_shift_zs_sig[transform_type],\n",
    "                                                    distrib_shift_actLevels[transform_type], k, threshold_sig, transform_type)\n",
    "    sig_distrib_shift_eval_results.append(current_eval_result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e643e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the distribution shift ood evaluation results\n",
    "save_list_to_csv(path_join(output_path, 'sig_distrib_shift_ood_eval_results'+csv_ext), sig_distrib_shift_eval_results, headers=knn_ood_eval_headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
